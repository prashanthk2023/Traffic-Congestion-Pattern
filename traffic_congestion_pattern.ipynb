{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from haversine import haversine_vector, Unit, haversine\n",
    "import osmnx as ox\n",
    "import pickle\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import folium\n",
    "from rtree import index\n",
    "import seaborn as sns\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Reading the Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ba8222469f7cf9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5c444c3a6c31f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops_df = pd.read_csv(r\"../Dataset/bus_stop.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b871044e81286d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gps_df = pd.read_csv(r\"../Dataset/GPS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd02695e7b4ba920",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(gps_df))\n",
    "gps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3520e27597bd953",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop duplicate based on DEVICE_ID, IST_DATE, LAT and LONGITUDE\n",
    "gps_df = gps_df.drop_duplicates(subset=['DEVICE_ID', 'IST_DATE', 'LAT', 'LONGITUDE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836d5faf87b54bb6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter the rows which LAT and LONGITUDE are between 12 and 14 and 77 and 79\n",
    "stops_df = stops_df[(stops_df['latitude_current'] > 12.8265) & (stops_df['latitude_current'] < 13.2694) & (\n",
    "        stops_df['longitude_current'] > 77.3740) & (stops_df['longitude_current'] < 77.8313)]\n",
    "gps_df = gps_df[(gps_df['LAT'] > 12) & (gps_df['LAT'] < 13.2694) & (gps_df['LONGITUDE'] > 77.3740) & (\n",
    "        gps_df['LONGITUDE'] < 77.8313)]\n",
    "print(len(gps_df))\n",
    "gps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a28ddd5002b5c45",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the data point based on year, Day and date\n",
    "gps_df['IST_DATE'] = pd.to_datetime(gps_df['IST_DATE'])\n",
    "gps_df['YEAR'] = gps_df['IST_DATE'].dt.year\n",
    "gps_df['DAY'] = gps_df['IST_DATE'].dt.dayofweek\n",
    "gps_df['DATE'] = gps_df['IST_DATE'].dt.date\n",
    "gps_df['TIME'] = gps_df['IST_DATE'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d8cbac53ee49f",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gps_df['DATE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31542f2a751040fe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove the data points which are not in 2019\n",
    "gps_df = gps_df[gps_df['YEAR'] == 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4106d9dea507f390",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort the dataframe by DEVICE_ID and then by IST_DATE\n",
    "gps_df = gps_df.sort_values(by=['DEVICE_ID', 'IST_DATE'])\n",
    "gps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c94ebc602feea2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Shift the rows by 1 and get the previous row's LAT and LONGITUDE and IST_DATE\n",
    "gps_df['PREV_LAT'] = gps_df.groupby(['DEVICE_ID'])['LAT'].shift(1)\n",
    "gps_df['PREV_LONGITUDE'] = gps_df.groupby(['DEVICE_ID'])['LONGITUDE'].shift(1)\n",
    "gps_df['PREV_IST_DATE'] = gps_df.groupby(['DEVICE_ID'])['IST_DATE'].shift(1)\n",
    "gps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e214a8295e529",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop the na values\n",
    "gps_df = gps_df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimating the speed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f108444bd323def5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52da9167fbe954c9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the distance between the current row and the previous row using haversine formula\n",
    "gps_df['DISTANCE'] = haversine_vector(gps_df[['LAT', 'LONGITUDE']], gps_df[['PREV_LAT', 'PREV_LONGITUDE']], Unit.METERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e781fc40785c39",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculate the time difference between the current row and the previous row\n",
    "gps_df['TIME_DIFF'] = (pd.to_datetime(gps_df['IST_DATE']) - pd.to_datetime(gps_df['PREV_IST_DATE'])).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dbba99",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gps_df))\n",
    "gps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf846f453e1584a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# PLot the distance and time difference\n",
    "plt.scatter(gps_df['DISTANCE'], gps_df['TIME_DIFF'])\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Time Difference')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a09d8fb6020e6c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gps_df['SPEED'] = gps_df['DISTANCE'] / (gps_df['TIME_DIFF'] + 0.0001) * 18 / 5\n",
    "\n",
    "# Plot the scatter plot speed with respect index\n",
    "plt.scatter(gps_df.index, gps_df['SPEED'])\n",
    "plt.ylim(0, 200)\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Speed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35188073cdddd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Value counts of speed between 0 and 1\n",
    "gps_df[(gps_df['SPEED'] > 0) & (gps_df['SPEED'] < 1)]['SPEED'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0ff4989291c83b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gps_df['SPEED'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df_copy = gps_df.copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8e1d45eadda3a91"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df = gps_df_copy.copy()\n",
    "gps_df = gps_df.loc[(gps_df[\"TIME_DIFF\"] < 70) & (gps_df[\"SPEED\"] < 100), :]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fab5666057fb4795"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimating the consecutive time at same location for each GPS ping"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7bc969aafc014cb8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915489b490d956e6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reset the index\n",
    "gps_df = gps_df.reset_index(drop=True)\n",
    "\n",
    "# Add column stop_time and initialize it with 0\n",
    "gps_df['STOP_TIME'] = 0\n",
    "\n",
    "# Take the dataframe with speed 0\n",
    "gps_df0 = gps_df[gps_df['SPEED'] <= 1]\n",
    "\n",
    "# Iterate over the dataframe with speed 0 and add the time_diff with the previous rows STOP_TIME to the current row STOP_TIME\n",
    "prev_index = 0\n",
    "for index,row in tqdm(gps_df0.iterrows(),total=len(gps_df0)):\n",
    "    if index > 0 and row['DEVICE_ID'] == gps_df0.loc[prev_index,'DEVICE_ID']:\n",
    "        gps_df.loc[index,'STOP_TIME'] = gps_df.loc[index-1,'STOP_TIME'] + row['TIME_DIFF']\n",
    "    else:\n",
    "        gps_df.loc[index,'STOP_TIME'] = row['TIME_DIFF']\n",
    "    prev_index = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the gps_df to csv\n",
    "gps_df.to_csv(r\"../Dataset/gps_point1.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "887ba4df6f85d0c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check Point 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c06bc9f2bcf362d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df = pd.read_csv(r\"../Dataset/gps_point1.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "206f0828305ee22a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df_copy = gps_df.copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0781e51"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assuming the GPS pings which are having STOP_TIME greater than 120 seconds as stops."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a10fedbbe851595"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d320e12343980035",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_time = 120\n",
    "gps_df = gps_df_copy.copy()\n",
    "st = gps_df.loc[gps_df['STOP_TIME'] > stop_time, ['LAT', 'LONGITUDE']].groupby(['LAT', 'LONGITUDE']).count()\n",
    "st = st.reset_index()\n",
    "len(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884a52e8fe9a9157",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter the gps_df with respect to STOP_TIME less than 600 and LAT and LONGITUDE are not in st\n",
    "gps_df = gps_df_copy.copy()\n",
    "gps_df = gps_df[gps_df['STOP_TIME'] < stop_time]\n",
    "\n",
    "gps_df = gps_df[\n",
    "    ~((gps_df['LAT'].isin(st['LAT'])) & (gps_df['LONGITUDE'].isin(st['LONGITUDE'])) & (gps_df['SPEED'] < 10))]\n",
    "\n",
    "len(gps_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df_copy = gps_df.copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5c9d3069a6b9677"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter the gps_df with repect to DEVICE_ID where total distance greater than 10000\n",
    "gps_df = gps_df_copy.copy()\n",
    "gps_df = gps_df.groupby(['DEVICE_ID']).filter(lambda x: x['DISTANCE'].sum() > 10000)\n",
    "len(gps_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dbede94e5a1946eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df.DEVICE_ID.value_counts().mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e5c45fe97e30e11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter the gps_df with repect to DEVICE_ID where number of pings greater than 1000\n",
    "gps_df2 = gps_df.groupby(['DEVICE_ID']).filter(lambda x: len(x) > 2000)\n",
    "len(gps_df2)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ebd92e3a1ac7851"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df_bus1 = gps_df.loc[gps_df['DEVICE_ID'] == 150218177, :]\n",
    "len(gps_df_bus1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46fa46673146d89"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a map for each Device ID and plot the gps pings as circular markers\n",
    "for device_id in gps_df['DEVICE_ID'].unique()[:5]:\n",
    "    gps_df_bus1 = gps_df.loc[gps_df['DEVICE_ID'] == device_id, :]\n",
    "    m = folium.Map(location=[12.9716, 77.5946], zoom_start=12)\n",
    "    for index, row in gps_df_bus1.iterrows():\n",
    "        folium.CircleMarker([row['LAT'], row['LONGITUDE']], radius=0.01, color='blue', fill=True).add_to(m)\n",
    "    m.save(f'./maps/bus_{device_id}.html')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c68e5f06fb1d7f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Filtering the GPS pings based on the Speed"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5051dcd02c96be2f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9ff56c1e305700",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Filter the gps data with respect to speed less than 120\n",
    "gps_df = gps_df[gps_df['SPEED'] < 120]\n",
    "print(gps_df.SPEED.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df_bus1_copy = gps_df_bus1.copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d32c2a6da93f913"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d5e8e9069797e4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gps_df_bus1 = gps_df.loc[gps_df['DEVICE_ID'] == 150218177, :]\n",
    "gps_df_bus1.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Bangalore Graph"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "12d28a965a3d85a2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "G = ox.graph_from_bbox(12.8265, 13.2694, 77.3740, 77.8313, network_type='drive')\n",
    "\n",
    "# edges from G\n",
    "edges = ox.graph_to_gdfs(G, nodes=False, edges=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6da46bdac5117053"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edges_df = pd.DataFrame(edges)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10ff2dcdd7565900"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# edges_df reset index\n",
    "edges_df = edges_df.reset_index(drop=False)\n",
    "# Filter the edges_df based on length\n",
    "edges_df = edges_df[(edges_df['length'] > 20) & (edges_df['length'] < 200)]\n",
    "\n",
    "# Consider only the columns osmid, highway, length, geometry,reversed, oneway, u,v\n",
    "edges_df = edges_df[['osmid', 'highway', 'length', 'geometry', 'reversed', 'oneway', 'u', 'v']]\n",
    "\n",
    "# Create lat_u, long_u, lat_v, long_v columns and assign from geometry\n",
    "edges_df['lat_u'] = edges_df['geometry'].apply(lambda x: x.coords[0][1])\n",
    "edges_df['long_u'] = edges_df['geometry'].apply(lambda x: x.coords[0][0])\n",
    "edges_df['lat_v'] = edges_df['geometry'].apply(lambda x: x.coords[-1][1])\n",
    "edges_df['long_v'] = edges_df['geometry'].apply(lambda x: x.coords[-1][0])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14a4561c2a5a1b52"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "edges_df.head(5)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e5b38820182805bf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Mapping the GPS pings to the nearest segment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f6f38331c8be8cb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2cda51be57469d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from rtree import index\n",
    "\n",
    "# Create an R-tree index\n",
    "idx = index.Index()\n",
    "\n",
    "# Populate the R-tree index with stop segments\n",
    "for i, row in tqdm(edges_df.iterrows(), total=len(edges_df)):\n",
    "    start_lat, start_lon, end_lat, end_lon = row['lat_u'], row['long_u'], row['lat_v'], row['long_v']\n",
    "    idx.insert(i, (min(start_lat, end_lat), min(start_lon, end_lon), max(start_lat, end_lat), max(start_lon, end_lon)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Function to find the stop segment for a given GPS ping\n",
    "def find_stop_segment(gps_lat, gps_lon):\n",
    "    for segment_id in idx.intersection((gps_lat, gps_lon, gps_lat, gps_lon)):\n",
    "        start_lat, start_lon, end_lat, end_lon = edges_df.loc[segment_id, ['lat_u', 'long_u', 'lat_v', 'long_v']]\n",
    "        if min(start_lat, end_lat) <= gps_lat <= max(start_lat, end_lat) and min(start_lon, end_lon) <= gps_lon <= max(\n",
    "                start_lon, end_lon):\n",
    "            l1 = haversine((gps_lat, gps_lon), (start_lat, start_lon), Unit.METERS)\n",
    "            l2 = haversine((gps_lat, gps_lon), (end_lat, end_lon), Unit.METERS)\n",
    "            l3 = haversine((start_lat, start_lon), (end_lat, end_lon), Unit.METERS)\n",
    "            if l1 + l2 <= 1.02 * l3:\n",
    "                return segment_id\n",
    "    return None  # GPS ping does not belong to any stop segment"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "57ae858cc02cd5b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d03c18a59917e7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a new column segment id and find it using find_stop_segment function using tqdm\n",
    "print(\"Mapping to nearest segment...\")\n",
    "length = len(gps_df)\n",
    "segment_list = []\n",
    "for index, row in tqdm(gps_df.iterrows(), total=length):\n",
    "    segment_list.append(find_stop_segment(row['LAT'], row['LONGITUDE']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df['segment_id'] = segment_list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ae898e1b4dddd3fb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the gps_df to csv\n",
    "gps_df.to_csv(r\"../Dataset/gps_point2.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "129eeb2b20a55f25"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the edges_df to csv\n",
    "edges_df.to_csv(r\"../Dataset/edges.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8a2335d3ef75ee82"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df.segment_id.notna().sum()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9df23c1495f2a3e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df.segment_id.value_counts().min()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22d0b913569d58f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df_1 = gps_df.loc[gps_df.segment_id.notna(), :]\n",
    "segments = gps_df_1.segment_id.unique().tolist()\n",
    "\n",
    "segments_df = edges_df.loc[edges_df.index.isin(segments), ['osmid', 'lat_u', 'long_u', 'lat_v', 'long_v']]\n",
    "# create folium map and plot the gps pings as circular markers and segments as lines and markers\n",
    "m = folium.Map(location=[12.9716, 77.5946], zoom_start=12)\n",
    "for index, row in tqdm(gps_df_1.iterrows()):\n",
    "    folium.CircleMarker([row['LAT'], row['LONGITUDE']], radius=0.01, color='blue', fill=True).add_to(m)\n",
    "for index, row in tqdm(segments_df.iterrows()):\n",
    "    folium.PolyLine([[row['lat_u'], row['long_u']], [row['lat_v'], row['long_v']]], color='red').add_to(m)\n",
    "    folium.Marker([row['lat_u'], row['long_u']], icon=folium.Icon(color='red')).add_to(m)\n",
    "    folium.Marker([row['lat_v'], row['long_v']], icon=folium.Icon(color='red')).add_to(m)\n",
    "m.save('bus1.html')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a7bdf0a7bd1e568f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "len(gps_df_bus1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2af81d49421d6042"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df_bus2 = gps_df_bus1.loc[gps_df_bus1.segment_id.notna(), :]\n",
    "segments = gps_df_bus2.segment_id.unique().tolist()\n",
    "\n",
    "segments_df = edges_df.loc[edges_df.index.isin(segments), ['osmid', 'lat_u', 'long_u', 'lat_v', 'long_v']]\n",
    "# create folium map and plot the gps pings as circular markers and segments as lines and markers\n",
    "m = folium.Map(location=[12.9716, 77.5946], zoom_start=12)\n",
    "for index, row in gps_df_bus2.iterrows():\n",
    "    folium.CircleMarker([row['LAT'], row['LONGITUDE']], radius=0.01, color='blue', fill=True).add_to(m)\n",
    "for index, row in segments_df.iterrows():\n",
    "    folium.PolyLine([[row['lat_u'], row['long_u']], [row['lat_v'], row['long_v']]], color='red').add_to(m)\n",
    "    folium.Marker([row['lat_u'], row['long_u']], icon=folium.Icon(color='red')).add_to(m)\n",
    "    folium.Marker([row['lat_v'], row['long_v']], icon=folium.Icon(color='red')).add_to(m)\n",
    "m.save('bus1.html')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f64fe9130209f01e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "##### Check Point 4"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "14df19493bbf7f7c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if './Dataset/gps_point2.csv' exists if yes read to gps_df\n",
    "if os.path.exists('./Dataset/gps_point2.csv'):\n",
    "    gps_df = pd.read_csv('./Dataset/gps_point2.csv')\n",
    "else:\n",
    "    print(\"File not found\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "159516f64f7bb574"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Check if './Dataset/edges.csv' exists if yes read to edges_df\n",
    "if os.path.exists('./Dataset/edges.csv'):\n",
    "    edges_df = pd.read_csv('./Dataset/edges.csv')\n",
    "else:\n",
    "    print(\"File not found\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19815057f6bb8049"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gps_df_copy = gps_df.copy()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8161607168f66ad6"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the data point based on year, Day and date\n",
    "gps_df['IST_DATE'] = pd.to_datetime(gps_df['IST_DATE'])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56cf888ef604a718"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Apply speed limit filter and remove the rows which are having speed greater than 120\n",
    "gps_df = gps_df[gps_df['SPEED'] < 120]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b291cbea790e4ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Remove the seged_id which are null\n",
    "gps_df = gps_df[gps_df['segment_id'].notna()]\n",
    "len(gps_df)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "160356a904c60506"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sum(gps_df.length > 5000)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "187b4768c87837eb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Consider only segments which are having pings count more than 200\n",
    "segments = gps_df.segment_id.value_counts()\n",
    "segments = segments[segments > 200]\n",
    "segments = segments.index.tolist()\n",
    "gps_df1 = gps_df[gps_df['segment_id'].isin(segments)]\n",
    "print(\"Length of gps_df\", len(gps_df1))\n",
    "print(\"No of segments\", len(segments))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "803feeb3eb8fe794"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create unique segments into dataframe\n",
    "segments_df1 = gps_df1[\n",
    "    ['segment_id', 'osmid', 'lat_u', 'long_u', 'lat_v', 'long_v', 'length', 'oneway', 'highway']].drop_duplicates()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4983195dcccb4c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create map and plot of the segments\n",
    "m = folium.Map(location=[12.9716, 77.5946], zoom_start=12)\n",
    "segments = segments_df.drop_duplicates(subset=['lat_u', 'long_u', 'lat_v', 'long_v'])\n",
    "for index, row in tqdm(segments.iterrows()):\n",
    "    if row['length'] < 20:\n",
    "        folium.PolyLine([[row['lat_u'], row['long_u']], [row['lat_v'], row['long_v']]], color='red').add_to(m)\n",
    "    elif row['length'] < 1000:\n",
    "        folium.PolyLine([[row['lat_u'], row['long_u']], [row['lat_v'], row['long_v']]], color='blue').add_to(m)\n",
    "    elif row['length'] < 4000:\n",
    "        folium.PolyLine([[row['lat_u'], row['long_u']], [row['lat_v'], row['long_v']]], color='brown').add_to(m)\n",
    "    else:\n",
    "        folium.PolyLine([[row['lat_u'], row['long_u']], [row['lat_v'], row['long_v']]], color='green').add_to(m)\n",
    "m.save('segments_4.html')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cbd327df72689f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dataframe based on the time hour  and count no of pings for each segment\n",
    "gps_df1['HOUR'] = gps_df1['IST_DATE'].apply(lambda x: x.hour)\n",
    "\n",
    "segments_df = gps_df1[['segment_id', 'HOUR']].groupby(['segment_id', 'HOUR']).size().reset_index(name='counts')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e88c4e547a513c5c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter the dataframe based on HOUR from 5 to 21\n",
    "segments_df = segments_df[(segments_df['HOUR'] >= 5) & (segments_df['HOUR'] <= 21)]\n",
    "\n",
    "# Consider the segments which are having pings across all the hours\n",
    "segments_df = segments_df.groupby(['segment_id']).filter(lambda x: len(x) >= 17)\n",
    "\n",
    "print(len(segments_df))\n",
    "print(len(segments_df.segment_id.unique()))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af747ee5aeb0565e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the length from segments_df1 and add it to segments_df using merge\n",
    "segments_df = segments_df.merge(segments_df1, on='segment_id', how='left')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94f4239eee7e098"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dataframe from gps_df1 and groupby segment_id and hour and get the mean of speed and std.dev of speed\n",
    "segments_df2 = gps_df1.groupby(['segment_id', 'HOUR']).agg({'SPEED': ['mean', 'std']}).reset_index()\n",
    "\n",
    "# Filter the dataframe based on HOUR from 5 to 21\n",
    "segments_df2 = segments_df2[(segments_df2['HOUR'] >= 5) & (segments_df2['HOUR'] <= 21)]\n",
    "\n",
    "# Consider the segments which are having pings across all the hours\n",
    "segments_df2 = segments_df2.groupby(['segment_id']).filter(lambda x: len(x) >= 17)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8239ad39d6a16e87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# reset the index\n",
    "segments_df2 = segments_df2.reset_index(drop=True)\n",
    "\n",
    "segments_df2.columns = ['segment_id', 'HOUR', 'AVG_SPEED', 'STD_DEV_SPEED']\n",
    "\n",
    "segments_df2.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a89d1a695a2bddb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a dataframe where it contains length, lat_u, long_u, lat_v, long_v and AVG_SPEED for each HOUR like AVG_SPEED_5, AVG_SPEED_6 etc\n",
    "segments_df3 = segments_df2.pivot(index='segment_id', columns='HOUR', values='AVG_SPEED').reset_index()\n",
    "segments_df4 = segments_df2.pivot(index='segment_id', columns='HOUR', values='STD_DEV_SPEED').reset_index()\n",
    "segments_df4.columns = ['segment_id'] + [f'v{i}' for i in segments_df4.columns[1:]]\n",
    "\n",
    "# Merge the segments_df3 with segments_df4\n",
    "segments_df3 = segments_df3.merge(segments_df4, on='segment_id', how='left')\n",
    "\n",
    "# Merge the segments_df3 with segments_df1\n",
    "segments_df3 = segments_df3.merge(segments_df1, on='segment_id', how='left')\n",
    "\n",
    "len(segments_df3)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d98fb96a05f699a7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "segments_df3.columns"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e61a3c1950582e60"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "segments_df3.to_csv(r\"./Dataset/segments_df4.csv\", index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8c19dc7c094248df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check Point 3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1beb28477597b26c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "segments_df3 = pd.read_csv(r\"./Dataset/segments_df3.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49a7e1b8e4fd77c3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert the column names from 5 to 22 if they string to int\n",
    "col_list = [str(i) for i in range(5, 22)]\n",
    "col_dict = {str(i): i for i in range(5, 22)}\n",
    "for col in col_list:\n",
    "    if col in segments_df3.columns.to_list():\n",
    "        segments_df3.rename(columns={col: int(col)}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e0c4041e6621db8c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a boxplot for each column\n",
    "col_list = [i for i in range(5, 22)]\n",
    "ax = sns.boxplot(data=segments_df3[col_list], width=0.75, showfliers=False)\n",
    "sns.stripplot(data=segments_df3[col_list], jitter=False, color='blue', alpha=0.1)\n",
    "\n",
    "mean_list = []\n",
    "# Plot means and connect them\n",
    "for i, col in enumerate(segments_df3[col_list].columns):\n",
    "    mean_val = segments_df3[col].mean()\n",
    "    mean_list.append(mean_val)\n",
    "    ax.scatter(i, mean_val, color='red', zorder=5)\n",
    "    if i > 1 and i < len(col_list) - 1:\n",
    "        ax.plot([i - 0.5, i + 0.5], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "    elif i == 1:\n",
    "        ax.plot([i - 1, i + 0.5], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "    elif i == len(col_list) - 1:\n",
    "        ax.plot([i - 0.5, i], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "    prev_mean = mean_val\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xticklabels(col_list)\n",
    "ax.set_xlabel('Hour')\n",
    "ax.set_ylabel('Average Speed (kmph)')\n",
    "ax.set_title('Total Average Speed')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "efe6a8e2ab25c7ff"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bar plot for oneway and highway\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "sns.countplot(x='oneway', data=segments_df3)\n",
    "# sns.countplot(x='highway', data=segments_df3, ax=ax[1],rotation=90)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7212f631f93151b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Distribution of lengths\n",
    "sns.distplot(segments_df3[segments_df3['length'] < 1000]['length'], kde=True, bins=100, color='orange')\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of segment lengths')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69cb450d27575ad8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# segments_df3.highway.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f1c9a94508debd8b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# # Replace the values in highway column using dictionary\n",
    "# word_dict = {'primary_link':'primary','secondary_link':'secondary','trunk_link':'trunk',\"['primary_link', 'primary']\":'primary',\n",
    "#              \"['secondary_link','secondary']\":'secondary',\"['trunk_link','trunk']\":'trunk','tertiary_link':'tertiary',\"['tertiary_link','tertiary']\":'tertiary','motorway_link':'motorway', 'unclassified': 'primary', \"['trunk', 'trunk_link']\": 'trunk', \"['trunk', 'primary']\" : 'primary', 'trunk':'primary',''}\n",
    "# segments_df3 = segments_df3.replace({\"highway\": word_dict})\n",
    "# segments_df3.highway.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41284ee68ea7b8a2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Descriptive Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d6483eebb9fbfa83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "segments_df3.describe()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a758fe4e41ebe17"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelling\n",
    "\n",
    "Modelling using different models\n",
    "\n",
    "1) Clustering using KMeans\n",
    "2) Clustering using DBSCAN\n",
    "3) Clustering using Spectral Clustering\n",
    "4) Clustering using Agglomerative Clustering\n",
    "5) Clustering using GMM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2da5d80c5c2ecce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Clustering the segments based on speeds\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "col_list = [i for i in range(5, 22)]\n",
    "# col_list.append('length')\n",
    "# col_list.append('oneway')\n",
    "wcss = []\n",
    "silhouette_scores = []\n",
    "X = np.array(segments_df3[col_list])\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "labels_dict = defaultdict(list)\n",
    "\n",
    "for i in range(1, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', max_iter=300, n_init=10, random_state=0)\n",
    "    labels_dict[i] = kmeans.fit_predict(X)\n",
    "    wcss.append(kmeans.inertia_)\n",
    "    if i> 1:\n",
    "        silhouette_scores.append(silhouette_score(X, labels_dict[i]))\n",
    "    if i==3:\n",
    "        cluster_centers_kmeans = kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "# Plot the graph to visualize the Elbow Method to find the optimal number of cluster and add dots at the points\n",
    "plt.plot(range(1, 11), wcss, color='blue', marker='o', markerfacecolor='red', markersize=3)\n",
    "# plt.scatter(range(1, 11), wcss, color='red')\n",
    "plt.title('The Elbow Method')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.xlim(1, 11)\n",
    "plt.ylabel('Within-cluster scatter, W')\n",
    "plt.show()\n",
    "\n",
    "# Silhouette Score\n",
    "plt.plot(range(2, 11), silhouette_scores, color='blue', marker='o', markerfacecolor='red', markersize=3)\n",
    "plt.title('The Silhouette Score')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "22622522ecae2bc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, labels in labels_dict.items():\n",
    "    m = folium.Map(location=[12.9716, 77.5946], zoom_start=12)\n",
    "    segments_df3['cluster'] = labels\n",
    "    colors_dict = {0: 'red', 1: 'blue', 2: 'green', 3: 'orange'}\n",
    "    for index, row in tqdm(segments_df3.iterrows()):\n",
    "        color = colors_dict[row['cluster']]\n",
    "        folium.PolyLine([[row['lat_u'], row['long_u']], [row['lat_v'], row['long_v']]], color=color).add_to(m)\n",
    "    m.save(f'{key}.html')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e14968884da85171"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Blox plots for every cluster based on results from the KMeans clustering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1466bfbb059330b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a boxplot for each column\n",
    "segments_df3['cluster'] = labels_dict[3]\n",
    "mean_dict = defaultdict(list)\n",
    "for l in set(labels):\n",
    "    df = segments_df3.loc[segments_df3['cluster'] == l, col_list]\n",
    "    col_list = [i for i in range(5, 22)]\n",
    "    plt.figure().patch.set_facecolor('white')\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    colors = sns.color_palette(\"pastel\")\n",
    "    ax = sns.boxplot(data=df, width=0.75, showfliers=False,  palette=colors)\n",
    "    sns.stripplot(data=df, jitter=False, color='blue', alpha=0.1)\n",
    "    \n",
    "    mean_list = []\n",
    "    # Plot means and connect them\n",
    "    for i, col in enumerate(df[col_list].columns):\n",
    "        mean_val = df[col].mean()\n",
    "        mean_list.append(mean_val)\n",
    "        ax.scatter(i, mean_val, color='red', zorder=5)\n",
    "        if i > 1 and i < len(col_list) - 1:\n",
    "            ax.plot([i - 0.5, i + 0.5], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "        elif i == 1:\n",
    "            ax.plot([i - 1, i + 0.5], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "        elif i == len(col_list) - 1:\n",
    "            ax.plot([i - 0.5, i], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "        prev_mean = mean_val\n",
    "    \n",
    "    mean_dict[l] = mean_list\n",
    "    # Set labels and title\n",
    "    ax.set_xticklabels(col_list)\n",
    "    ax.set_xlabel('Hour')\n",
    "    ax.set_ylabel('Average Speed (kmph)')\n",
    "    ax.set_title(f'Total Average Speed across cluster_{l+1}')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7da496356cdb55a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting the mean values of each cluster across the hours\n",
    "for l in set(labels):\n",
    "    plt.plot(mean_dict[l], label=f'cluster_{l+1}')\n",
    "plt.legend()\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Average Speed (kmph)')\n",
    "plt.title('Average Speed across clusters (KMeans before reduction)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b41015c933216d51"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Hierarchical Clustering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c42924d82e77949e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "segments_df3.cluster.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a8e643bfbb5679ce"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Clustering using Heirarchical Clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "col_list = [i for i in range(5, 22)]\n",
    "silhouette_scores = []\n",
    "# scaler = StandardScaler()\n",
    "# X = scaler.fit_transform(segments_df3[col_list])\n",
    "X = np.array(segments_df3[col_list])\n",
    "labels_dict_heir = defaultdict(list)\n",
    "metrics = ['euclidean', 'l1']\n",
    "\n",
    "for metric in metrics:\n",
    "    for i in range(2, 4):\n",
    "        model = AgglomerativeClustering(n_clusters=i, metric='l1', linkage='average')\n",
    "        labels_dict_heir[f'{metric}_{i}'] = model.fit_predict(X)\n",
    "        silhouette_scores.append(silhouette_score(X, labels))\n",
    "\n",
    "\n",
    "\n",
    "# Plot the graph to visualize the Silhouette Score to find the optimal number of cluster\n",
    "# plt.plot(range(2,11),silhouette_scores)\n",
    "# plt.title('The Silhouette Score')\n",
    "# plt.xlabel('Number of clusters')\n",
    "# plt.ylabel('Silhouette Score')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2882bbabcb95686c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Folium maps for different number of cluster based on results from the Agglomerative Clustering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3a377909ba43d84"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a folium map and plot the segments based on cluster and color is based on cluster\n",
    "for key, labels in labels_dict_heir.items():\n",
    "    m = folium.Map(location=[12.9716, 77.5946], zoom_start=12)\n",
    "    segments_df3['cluster'] = labels\n",
    "    colors_dict = {0: 'red', 1: 'blue', 2: 'green', 3: 'orange'}\n",
    "    for index, row in tqdm(segments_df3.iterrows()):\n",
    "        color = colors_dict[row['cluster']]\n",
    "        folium.PolyLine([[row['lat_u'], row['long_u']], [row['lat_v'], row['long_v']]], color=color).add_to(m)\n",
    "    m.save(f'./Maps/{key}.html')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "50d8159b2174dd51"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Box plots for every cluster based on results from the Agglomerative Clustering"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10c71d035478f34c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "segments_df3['cluster'] = labels_dict_heir[f'{metrics[1]}_{3}']\n",
    "labels = labels_dict_heir[f'{metrics[1]}_{3}']\n",
    "mean_dict = defaultdict(list)\n",
    "for l in set(labels):\n",
    "    df = segments_df3.loc[segments_df3['cluster'] == l, col_list]\n",
    "    col_list = [i for i in range(5, 22)]\n",
    "    plt.figure().patch.set_facecolor('white')\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    colors = sns.color_palette(\"pastel\")\n",
    "    ax = sns.boxplot(data=df, width=0.75, showfliers=False,  palette=colors)\n",
    "    sns.stripplot(data=df, jitter=False, color='blue', alpha=0.1)\n",
    "    \n",
    "    mean_list = []\n",
    "    # Plot means and connect them\n",
    "    for i, col in enumerate(df[col_list].columns):\n",
    "        mean_val = df[col].mean()\n",
    "        mean_list.append(mean_val)\n",
    "        ax.scatter(i, mean_val, color='red', zorder=5)\n",
    "        if i > 1 and i < len(col_list) - 1:\n",
    "            ax.plot([i - 0.5, i + 0.5], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "        elif i == 1:\n",
    "            ax.plot([i - 1, i + 0.5], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "        elif i == len(col_list) - 1:\n",
    "            ax.plot([i - 0.5, i], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "        prev_mean = mean_val\n",
    "    mean_dict[l] = mean_list\n",
    "    # Set labels and title\n",
    "    ax.set_xticklabels(col_list)\n",
    "    ax.set_xlabel('Hour')\n",
    "    ax.set_ylabel('Average Speed (kmph)')\n",
    "    ax.set_title(f'Total Average Speed across cluster_{l+1}')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f41971a2051c63ac"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting the mean values of each cluster across the hours\n",
    "for l in set(labels):\n",
    "    plt.plot(mean_dict[l], label=f'cluster_{l + 1}')\n",
    "plt.legend()\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Average Speed (kmph)')\n",
    "plt.title('Average Speed across clusters (Hierarchical before reduction)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "179c19e7881f6acf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "segments_df3.cluster.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1e18562ec4f2c2f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Print the segments which are values of all columns in col_list more than 50\n",
    "col_list = [i for i in range(5, 22)]\n",
    "segments_df3[(segments_df3[col_list] > 50).all(axis=1)]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aafe3ec17c760693"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "8ade235263c90428"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Guassian Mixture Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77c7e2248521ea3a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Clustering using GMM\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "col_list = [i for i in range(5, 22)]\n",
    "silhouette_scores = []\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(segments_df3[col_list])\n",
    "labels_dict_gmm = defaultdict(list)\n",
    "\n",
    "for i in range(2, 11):\n",
    "    model = GaussianMixture(n_components=i, covariance_type='spherical')\n",
    "    labels_dict_gmm[i] = model.fit_predict(X)\n",
    "    silhouette_scores.append(silhouette_score(X, labels))\n",
    "    if i == 3:\n",
    "        cluster_centers_gmm = model.means_\n",
    "\n",
    "# Plot the graph to visualize the Silhouette Score to find the optimal number of cluster\n",
    "plt.plot(range(2,11),silhouette_scores)\n",
    "plt.title('The Silhouette Score')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.show()\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "917eb72b2e05b60a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "segments_df3.cluster.value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "16700325bdae2a2b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Folium maps for different number of cluster based on results from the GMM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "301d52035156d558"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for key, labels in labels_dict_gmm.items():\n",
    "    if key > 3:\n",
    "        continue\n",
    "    m = folium.Map(location=[12.9716, 77.5946], zoom_start=12)\n",
    "    segments_df3['cluster'] = labels\n",
    "    colors_dict = {0: 'red', 1: 'blue', 2: 'green', 3: 'orange'}\n",
    "    for index, row in tqdm(segments_df3.iterrows()):\n",
    "        color = colors_dict[row['cluster']]\n",
    "        folium.PolyLine([[row['lat_u'], row['long_u']], [row['lat_v'], row['long_v']]], color=color).add_to(m)\n",
    "    m.save(f'GMM_{key}.html')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "58fd4aee5693b2d1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Box plots for every cluster based on results from the GMM"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b6d84ea961e3d781"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "segments_df3['cluster'] = labels_dict_gmm[3]\n",
    "labels = labels_dict_gmm[3]\n",
    "mean_dict = defaultdict(list)\n",
    "for l in set(labels):\n",
    "    df = segments_df3.loc[segments_df3['cluster'] == l, col_list]\n",
    "    col_list = [i for i in range(5, 22)]\n",
    "    plt.figure().patch.set_facecolor('white')\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    colors = sns.color_palette(\"pastel\")\n",
    "    ax = sns.boxplot(data=df, width=0.75, showfliers=False,  palette=colors)\n",
    "    sns.stripplot(data=df, jitter=False, color='blue', alpha=0.1)\n",
    "    \n",
    "    mean_list = []\n",
    "    # Plot means and connect them\n",
    "    for i, col in enumerate(df[col_list].columns):\n",
    "        mean_val = df[col].mean()\n",
    "        mean_list.append(mean_val)\n",
    "        ax.scatter(i, mean_val, color='red', zorder=5)\n",
    "        if i > 1 and i < len(col_list) - 1:\n",
    "            ax.plot([i - 0.5, i + 0.5], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "        elif i == 1:\n",
    "            ax.plot([i - 1, i + 0.5], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "        elif i == len(col_list) - 1:\n",
    "            ax.plot([i - 0.5, i], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "        prev_mean = mean_val\n",
    "    \n",
    "    mean_dict[l] = mean_list\n",
    "    # Set labels and title\n",
    "    ax.set_xticklabels(col_list)\n",
    "    ax.set_xlabel('Hour')\n",
    "    ax.set_ylabel('Average Speed (kmph)')\n",
    "    ax.set_title(f'Total Average Speed across cluster_{l+1}')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "537d47029db8dfc7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plotting the mean values of each cluster across the hours\n",
    "for l in set(labels):\n",
    "    plt.plot(mean_dict[l], label=f'cluster_{l + 1}')\n",
    "plt.legend()\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Average Speed (kmph)')\n",
    "plt.title('Average Speed across clusters (GMM before Reduction)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e8f05b8f45ebf05"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing the data visualizations\n",
    "\n",
    "1) Comparing the removal of Depot pings present in the GPS data\n",
    "2) Comparing the removal of pings with speed greater than 120 kmph\n",
    "3) "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9dee03860e45bb09"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a folium map of GPS pings for top 5 devices\n",
    "m = folium.Map(location=[12.9716, 77.5946], zoom_start=12)\n",
    "for device_id in gps_df['DEVICE_ID'].value_counts(ascending=False).head(5).index.tolist():\n",
    "    gps_df_bus1 = gps_df.loc[gps_df['DEVICE_ID'] == device_id, :]\n",
    "    for index, row in gps_df_bus1.iterrows():\n",
    "        folium.CircleMarker([row['LAT'], row['LONGITUDE']], radius=0.01, color='blue', fill=True).add_to(m)\n",
    "m.save('After_depot_pings.html')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f846f2d24435b2f7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Read the './Dataset/GPS.csv' file to gps_df10\n",
    "gps_df10 = pd.read_csv('./Dataset/GPS.csv')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5522144a8551e572"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a folium map of GPS pings for same devices earlier\n",
    "m = folium.Map(location=[12.9716, 77.5946], zoom_start=12)\n",
    "for device_id in gps_df['DEVICE_ID'].value_counts(ascending=False).head(5).index.tolist():\n",
    "    gps_df_bus1 = gps_df10.loc[gps_df10['DEVICE_ID'] == device_id, :]\n",
    "    for index, row in gps_df_bus1.iterrows():\n",
    "        folium.CircleMarker([row['LAT'], row['LONGITUDE']], radius=0.01, color='blue', fill=True).add_to(m)\n",
    "m.save('Before_depot_pings.html')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d090603b94c3f48"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Distribution of number of segements based on minimum speed across time intervals"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1c8a3a80fcbb35d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Finding the column in col_list which are having minimum across each row\n",
    "col_list = [i for i in range(5, 22)]\n",
    "x_labels = [f'AvgSpeed{(i,i+1)}' for i in range(5, 22)]\n",
    "segments_df3['min_column'] = segments_df3[col_list].idxmin(axis=1)\n",
    "\n",
    "# Plot the bar plot for min column\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.bar(segments_df3['min_column'].value_counts().index, segments_df3['min_column'].value_counts().values)\n",
    "plt.xlabel('Time interval')\n",
    "plt.xticks(ticks=range(5, 22), labels=x_labels, rotation=45, ha='right')\n",
    "plt.xlim(4,22)\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of number of segements based on minimum speed across time intervals')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c109935b1906bc0f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Correlation matrix for segments_df3 of columns in col_list\n",
    "col_list = [i for i in range(5, 22)]\n",
    "col_dict = [f'AvgSpeed{(i,i+1)}' for i in range(5, 22)]\n",
    "# col_list.append('length')\n",
    "corr = segments_df3[col_list].corr()\n",
    "\n",
    "# Plot the heatmap for correlation matrix\n",
    "plt.figure(figsize=(15, 5))\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm')\n",
    "\n",
    "# Indices as in col_dict\n",
    "plt.xticks(ticks=range(len(col_list)), labels=col_dict, rotation=45)\n",
    "plt.yticks(ticks=range(len(col_list)), labels=col_dict, rotation=0)\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e69b1238cf848cd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Dimension reduction Analysis "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "908fc4d5e31b697"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# PCA for segments_df3 of columns in col_list\n",
    "col_list = [i for i in range(5, 22)]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(segments_df3[col_list])\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "\n",
    "# Variance explained by each principal component\n",
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "\n",
    "# Cumulative variance explained\n",
    "cumulative_variance_ratio = np.cumsum(explained_variance_ratio)\n",
    "\n",
    "# Plot the explained variance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(explained_variance_ratio) + 1), cumulative_variance_ratio, marker='o', linestyle='-', color='b')\n",
    "plt.title('Cumulative Variance Explained by Principal Components')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Variance Explained')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76c776c1b3e226d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the scatter plot for PCA based on first two components\n",
    "cluster_centers_kmeans_red = pca.transform(cluster_centers_kmeans)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels_dict[3], cmap='viridis')\n",
    "plt.scatter(cluster_centers_kmeans_red[:, 0], cluster_centers_kmeans_red[:, 1],c=list(set(labels_dict[3])), cmap='coolwarm', s=100)\n",
    "plt.title('PCA Scatter Plot (Without Reduction Clustering using Kmeans)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax.view_init(elev=20, azim=30)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c=labels_dict[3], cmap='viridis')\n",
    "ax.scatter(cluster_centers_kmeans_red[:, 0], cluster_centers_kmeans_red[:, 1], cluster_centers_kmeans_red[:, 2],c=list(set(labels_dict[3])), cmap='coolwarm', s=100)\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.set_title('PCA Scatter Plot (Without Reduction Clustering using Kmeans)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d23ede17beb704f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the scatter plot for PCA based on first two components\n",
    "cluster_centers_gmm_red = pca.transform(cluster_centers_gmm)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels_dict_gmm[3], cmap='viridis')\n",
    "plt.scatter(cluster_centers_gmm_red[:, 0], cluster_centers_gmm_red[:, 1],c=list(set(labels_dict_gmm[3])), cmap='coolwarm', s=100)\n",
    "plt.title('PCA Scatter Plot (Without Reduction Clustering using GMM)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax.view_init(elev=20, azim=30)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X_pca[:, 0], X_pca[:, 1], X_pca[:, 2], c=labels_dict_gmm[3], cmap='viridis')\n",
    "ax.scatter(cluster_centers_gmm_red[:, 0], cluster_centers_gmm_red[:, 1], cluster_centers_gmm_red[:, 2],c=list(set(labels_dict_gmm[3])), cmap='coolwarm', s=100)\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.set_title('PCA Scatter Plot (Without Reduction Clustering using GMM)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20d4f66ae556503d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Non-linear dimension reduction using MDS\n",
    "\n",
    "from sklearn.manifold import MDS\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "mds = MDS(n_components= 3,metric=False, dissimilarity='precomputed', random_state=0, max_iter=3000, eps=1e-4, normalized_stress=True)\n",
    "col_list = [i for i in range(5, 22)]\n",
    "X_mds = mds.fit_transform(euclidean_distances(X))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5c8087c4f078e1f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the scatter plot for PCA based on first two components\n",
    "# cluster_centers_kmeans_red = mds.transform(cluster_centers_kmeans)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_mds[:, 0], X_mds[:, 1], c=labels_dict[3], cmap='viridis')\n",
    "# plt.scatter(cluster_centers_kmeans_red[:, 0], cluster_centers_kmeans_red[:, 1],c=list(set(labels_dict[3])), cmap='coolwarm', s=100)\n",
    "plt.title('PCA Scatter Plot (Without Reduction Clustering using Kmeans)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax.view_init(elev=20, azim=30)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X_mds[:, 0], X_mds[:, 1], X_mds[:, 2], c=labels_dict[3], cmap='viridis')\n",
    "# ax.scatter(cluster_centers_kmeans_red[:, 0], cluster_centers_kmeans_red[:, 1], cluster_centers_kmeans_red[:, 2],c=list(set(labels_dict[3])), cmap='coolwarm', s=100)\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.set_title('PCA Scatter Plot (Without Reduction Clustering using Kmeans)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eddf1ffd6c34dfeb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the scatter plot for PCA based on first two components\n",
    "# cluster_centers_gmm_red = mds.transform(cluster_centers_gmm)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_mds[:, 0], X_mds[:, 1], c=labels_dict_gmm[3], cmap='viridis')\n",
    "# plt.scatter(cluster_centers_gmm_red[:, 0], cluster_centers_gmm_red[:, 1],c=list(set(labels_dict_gmm[3])), cmap='coolwarm', s=100)\n",
    "plt.title('PCA Scatter Plot (Without Reduction Clustering using GMM)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax.view_init(elev=20, azim=30)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X_mds[:, 0], X_mds[:, 1], X_mds[:, 2], c=labels_dict_gmm[3], cmap='viridis')\n",
    "# ax.scatter(cluster_centers_gmm_red[:, 0], cluster_centers_gmm_red[:, 1], cluster_centers_gmm_red[:, 2],c=list(set(labels_dict_gmm[3])), cmap='coolwarm', s=100)\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.set_title('PCA Scatter Plot (Without Reduction Clustering using GMM)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e01157665b9dc211"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Non-linear dimension reduction using Kernel PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import manhattan_distances, euclidean_distances\n",
    "\n",
    "col_list = [i for i in range(5, 22)]\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(segments_df3[col_list])\n",
    "\n",
    "kpca = KernelPCA(n_components=3, kernel='rbf')\n",
    "X_kpca = kpca.fit_transform(X)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7cb72c85d4c5c1c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the scatter plot for PCA based on first two components\n",
    "cluster_centers_kmeans_red = kpca.transform(cluster_centers_kmeans)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_kpca[:, 0], X_kpca[:, 1], c=labels_dict[3], cmap='viridis')\n",
    "plt.scatter(cluster_centers_kmeans_red[:, 0], cluster_centers_kmeans_red[:, 1],c=list(set(labels_dict[3])), cmap='coolwarm', s=100)\n",
    "plt.title('PCA Scatter Plot (Without Reduction Clustering using Kmeans)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax.view_init(elev=20, azim=30)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X_kpca[:, 0], X_kpca[:, 1], X_kpca[:, 2], c=labels_dict[3], cmap='viridis')\n",
    "ax.scatter(cluster_centers_kmeans_red[:, 0], cluster_centers_kmeans_red[:, 1], cluster_centers_kmeans_red[:, 2],c=list(set(labels_dict[3])), cmap='coolwarm', s=100)\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.set_title('PCA Scatter Plot (Without Reduction Clustering using Kmeans)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69b5e5c6974208d7"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Kmeans clustering after dimension reduction\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "col_list = [i for i in range(5, 22)]\n",
    "kmeans = KMeans(n_clusters=3, random_state=0)\n",
    "labels_dict['3_reduced'] = kmeans.fit_predict(X_kpca)\n",
    "cluster_centers_kmeans_red = kmeans.cluster_centers_"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6dcb58e590e4cb61"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Plot the scatter plot for PCA based on first two components\n",
    "# cluster_centers_kmeans_red = kpca.transform(cluster_centers_kmeans)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_kpca[:, 0], X_kpca[:, 1], c=labels_dict['3_reduced'], cmap='viridis')\n",
    "plt.scatter(cluster_centers_kmeans_red[:, 0], cluster_centers_kmeans_red[:, 1],c=list(set(labels_dict['3_reduced'])), cmap='coolwarm', s=100)\n",
    "plt.title('PCA Scatter Plot (Without Reduction Clustering using Kmeans)')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "\n",
    "ax.view_init(elev=20, azim=30)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax.scatter(X_kpca[:, 0], X_kpca[:, 1], X_kpca[:, 2], c=labels_dict['3_reduced'], cmap='viridis')\n",
    "ax.scatter(cluster_centers_kmeans_red[:, 0], cluster_centers_kmeans_red[:, 1], cluster_centers_kmeans_red[:, 2],c=list(set(labels_dict['3_reduced'])), cmap='coolwarm', s=100)\n",
    "ax.set_xlabel('Principal Component 1')\n",
    "ax.set_ylabel('Principal Component 2')\n",
    "ax.set_zlabel('Principal Component 3')\n",
    "ax.set_title('PCA Scatter Plot (Without Reduction Clustering using Kmeans)')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "296e5fb7b736dcce"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Check Point 3"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ddfa548e972c3b83"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#### Check Point 3\n",
    "segments_df4 = pd.read_csv(r\"./Dataset/segments_df4.csv\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c78df1b83d676df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert the column names from 5 to 22 if they string to int\n",
    "col_list = [str(i) for i in range(5, 22)]\n",
    "col_dict = {str(i): i for i in range(5, 22)}\n",
    "for col in col_list:\n",
    "    if col in segments_df3.columns.to_list():\n",
    "        segments_df4.rename(columns={col: int(col)}, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3afd0920d5f1cd15"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a boxplot for each column\n",
    "col_list = [i for i in range(5, 22)]\n",
    "var_col_list = [f'v{i}' for i in range(5, 22)]\n",
    "ax = sns.boxplot(data=segments_df3[col_list], width=0.75, showfliers=False)\n",
    "sns.stripplot(data=segments_df3[col_list], jitter=False, color='blue', alpha=0.1)\n",
    "\n",
    "mean_list = []\n",
    "var_list = []\n",
    "# Plot means and connect them\n",
    "for i, col in enumerate(segments_df3[col_list].columns):\n",
    "    mean_val = segments_df3[col].mean()\n",
    "    var_val = segments_df3[f'v{col}'].mean()\n",
    "    mean_list.append(mean_val)\n",
    "    var_list.append(var_val)\n",
    "    ax.scatter(i, mean_val, color='red', zorder=5)\n",
    "    if i > 1 and i < len(col_list) - 1:\n",
    "        ax.plot([i - 0.5, i + 0.5], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "    elif i == 1:\n",
    "        ax.plot([i - 1, i + 0.5], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "    elif i == len(col_list) - 1:\n",
    "        ax.plot([i - 0.5, i], [prev_mean, mean_val], color='red', linestyle='-', linewidth=2)\n",
    "    prev_mean = mean_val\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xticklabels(col_list)\n",
    "ax.set_xlabel('Hour')\n",
    "ax.set_ylabel('Average Speed (kmph)')\n",
    "ax.set_title('Total Average Speed')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ea89e9106c60ed75"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create line plot for mean of each column joining the col_list and var_list\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(col_list, mean_list, marker='o', linestyle='-', color='b')\n",
    "plt.plot(col_list, var_list,  marker='o', linestyle='-', color='r')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Average Speed (kmph)')\n",
    "plt.title('Total Average Speed')\n",
    "plt.legend(['Mean', 'Variance'])\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c069e872881f1b4b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bar plot for oneway and highway\n",
    "# fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
    "sns.countplot(x='oneway', data=segments_df3)\n",
    "# sns.countplot(x='highway', data=segments_df3, ax=ax[1],rotation=90)\n",
    "plt.show()\n",
    "# Distribution of lengths\n",
    "sns.distplot(segments_df3[segments_df3['length'] < 1000]['length'], kde=True, bins=100, color='orange')\n",
    "plt.xlabel('length')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Distribution of segment lengths')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3f5b22246b439527"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
